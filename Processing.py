import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

class EnhancedDataPreprocessor:
    """ì¹˜ë£Œ ì´ë ¥ í¬í•¨ ê°•í™”ëœ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, picture_strategy='zero', decibel_strategy='period_avg', lux_strategy='period_avg'):
        """
        ëˆ„ë½ ë°ì´í„° ì²˜ë¦¬ ì „ëµ ì„¤ì •
        
        Parameters:
        -----------
        picture_strategy : str
            - 'zero': ëˆ„ë½ì‹œ 0ìœ¼ë¡œ ì„¤ì •
            - 'period_avg': ëŒ€ìƒì í•´ë‹¹ ê¸°ê°„ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
            - 'missing': ì¸¡ì • ì•ˆë¨ì„ ë³„ë„ ê°’(-999)ìœ¼ë¡œ í‘œì‹œ
        """
        self.picture_strategy = picture_strategy
        self.decibel_strategy = decibel_strategy
        self.lux_strategy = lux_strategy
        
        print(f"ëˆ„ë½ ë°ì´í„° ì²˜ë¦¬ ì „ëµ: ì‚¬ì§„={self._get_strategy_name(picture_strategy)}, "
            f"DECIBEL={self._get_strategy_name(decibel_strategy)}, LUX={self._get_strategy_name(lux_strategy)}")

    def _get_strategy_name(self, strategy):
        """ì „ëµ ì´ë¦„ ë³€í™˜"""
        names = {
            'zero': '0ìœ¼ë¡œ ì„¤ì •', 
            'period_avg': 'ê¸°ê°„ í‰ê·  ëŒ€ì²´',
            'missing': 'ì¸¡ì •ì•ˆë¨(-999)'
        }
        return names.get(strategy, strategy)    
    
    def load_data(self, data_file, label_file):
        print("1: ë°ì´í„° ë¡œë“œ")
        
        # ë¼ë²¨ ë°ì´í„° ë¡œë“œ (ì‹œíŠ¸ëª…ì´ 'MZ'ì„)
        labels_df = pd.read_excel(label_file, sheet_name='MZ')
        if 'group' in labels_df.columns:
            labels_df['group'] = labels_df['group'].str.strip()
            print(f"ë¼ë²¨ ë¶„í¬: {labels_df['group'].value_counts().to_dict()}")
        
        # ê° ë°ì´í„° ì‹œíŠ¸ ë¡œë“œ
        data_sheets = {}
        sheet_names = ['STEP', 'PICTURE', 'LUX', 'DECIBEL', 'JOIN SURVEY']
        
        for sheet in sheet_names:
            try:
                data_sheets[sheet] = pd.read_excel(data_file, sheet_name=sheet)
                print(f"{sheet}: {len(data_sheets[sheet])}ê°œ ë ˆì½”ë“œ")
            except Exception as e:
                print(f"{sheet} ë¡œë“œ ì‹¤íŒ¨: {e}")
                data_sheets[sheet] = pd.DataFrame()
        
        return data_sheets, labels_df
    
    def process_step_data(self, step_data):
        """Step 2: STEP ë°ì´í„° ì „ì²˜ë¦¬"""
        print("\n=== Step 2: STEP ë°ì´í„° ì „ì²˜ë¦¬ ===")
        
        clean_step_data = []
        
        for _, row in step_data.iterrows():
            # STEP_DATEë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš© (YYYYMMDD)
            step_date = int(row['STEP_DATE'])
            
            clean_step_data.append({
                'USER_ID': row['USER_ID'],
                'DATE': step_date,
                'DAILY_STEPS': row['STEP_COUNT']
            })
        
        print(f"ì •ë¦¬ëœ STEP ë°ì´í„°: {len(clean_step_data)}ê°œ ì¼ë³„ í–‰")
        return clean_step_data
    
    def extract_date_from_timestamp(self, timestamp):
        """íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (YYYYMMDDHHMM -> YYYYMMDD)"""
        timestamp_str = str(timestamp)
        if len(timestamp_str) >= 8:
            return int(timestamp_str[:8])
        return None
    
    def find_densest_7day_period(self, user_id, clean_step_data, lux_data, decibel_data, picture_data):
        """ì‚¬ìš©ìë³„ ê°€ì¥ ë°€ë„ ë†’ì€ 7ì¼ êµ¬ê°„ ì°¾ê¸°"""
        
        # ì‚¬ìš©ìì˜ ëª¨ë“  ë°ì´í„° ë‚ ì§œ ìˆ˜ì§‘
        user_step_data = [r for r in clean_step_data if r['USER_ID'] == user_id]
        if len(user_step_data) < 3:
            return None
        
        # ì‚¬ìš©ìì˜ ëª¨ë“  í™œë™ ë‚ ì§œ ìˆ˜ì§‘
        all_dates = set()
         
        # STEP ë‚ ì§œë“¤
        step_dates = [r['DATE'] for r in user_step_data]
        all_dates.update(step_dates)
        
        # LUX ë‚ ì§œë“¤
        if not lux_data.empty:
            user_lux = lux_data[lux_data['USER_ID'].astype(str) == str(user_id)]
            for _, row in user_lux.iterrows():
                if pd.notna(row.get('LUX_TIME')):
                    date = self.extract_date_from_timestamp(row['LUX_TIME'])
                    if date:
                        all_dates.add(date)
        
        # DECIBEL ë‚ ì§œë“¤
        if not decibel_data.empty:
            user_decibel = decibel_data[decibel_data['USER_ID'].astype(str) == str(user_id)]
            for _, row in user_decibel.iterrows():
                if pd.notna(row.get('DB_TIME')):
                    date = self.extract_date_from_timestamp(row['DB_TIME'])
                    if date:
                        all_dates.add(date)
        
        # PICTURE ë‚ ì§œë“¤
        if not picture_data.empty:
            user_pictures = picture_data[picture_data['USER_ID'].astype(str) == str(user_id)]
            for _, row in user_pictures.iterrows():
                if pd.notna(row.get('PICTURE_DATE')):
                    date = self.extract_date_from_timestamp(row['PICTURE_DATE'])
                    if date:
                        all_dates.add(date)
        
        # ë‚ ì§œë“¤ì„ ì •ë ¬
        sorted_dates = sorted(list(all_dates))
        
        if len(sorted_dates) < 7:
            return sorted_dates
        
        # ëª¨ë“  ê°€ëŠ¥í•œ 7ì¼ êµ¬ê°„ì— ëŒ€í•´ ë°€ë„ ê³„ì‚°
        best_period = None
        best_density = 0
        
        for i in range(len(sorted_dates) - 6):
            period_dates = sorted_dates[i:i+7]
            
            start_date = datetime.strptime(str(period_dates[0]), '%Y%m%d')
            end_date = datetime.strptime(str(period_dates[-1]), '%Y%m%d')
            
            if (end_date - start_date).days <= 10:
                density = self.calculate_period_density(user_id, period_dates, 
                                                      clean_step_data, lux_data, decibel_data, picture_data)
                
                if density > best_density:
                    best_density = density
                    best_period = period_dates
        
        return best_period if best_period else sorted_dates[:7]
    
    def calculate_period_density(self, user_id, period_dates, clean_step_data, lux_data, decibel_data, picture_data):
        """íŠ¹ì • ê¸°ê°„ì˜ ë°ì´í„° ë°€ë„ ê³„ì‚°"""
        start_date = min(period_dates)
        end_date = max(period_dates)
        
        density_score = 0
        total_possible = len(period_dates)
        
        # STEP ë°ì´í„° ë°€ë„
        step_days = len([r for r in clean_step_data 
                        if r['USER_ID'] == user_id and start_date <= r['DATE'] <= end_date])
        step_density = step_days / total_possible
        density_score += step_density * 0.4
        
        # LUX ë°ì´í„° ë°€ë„
        if not lux_data.empty:
            user_lux = lux_data[lux_data['USER_ID'].astype(str) == str(user_id)]
            lux_dates = set()
            for _, row in user_lux.iterrows():
                if pd.notna(row.get('LUX_TIME')):
                    date = self.extract_date_from_timestamp(row['LUX_TIME'])
                    if date and start_date <= date <= end_date:
                        lux_dates.add(date)
            lux_density = len(lux_dates) / total_possible
            density_score += lux_density * 0.2
        
        # DECIBEL ë°ì´í„° ë°€ë„
        if not decibel_data.empty:
            user_decibel = decibel_data[decibel_data['USER_ID'].astype(str) == str(user_id)]
            decibel_dates = set()
            for _, row in user_decibel.iterrows():
                if pd.notna(row.get('DB_TIME')):
                    date = self.extract_date_from_timestamp(row['DB_TIME'])
                    if date and start_date <= date <= end_date:
                        decibel_dates.add(date)
            decibel_density = len(decibel_dates) / total_possible
            density_score += decibel_density * 0.2
        
        # PICTURE ë°ì´í„° ë°€ë„
        if not picture_data.empty:
            user_pictures = picture_data[picture_data['USER_ID'].astype(str) == str(user_id)]
            picture_dates = set()
            for _, row in user_pictures.iterrows():
                if pd.notna(row.get('PICTURE_DATE')):
                    date = self.extract_date_from_timestamp(row['PICTURE_DATE'])
                    if date and start_date <= date <= end_date:
                        picture_dates.add(date)
            picture_density = len(picture_dates) / total_possible
            density_score += picture_density * 0.2
        
        return density_score
    
    def create_7day_features(self, clean_step_data, lux_data, decibel_data, picture_data, all_user_ids):
        """Step 3: ë°€ë„ ê¸°ë°˜ 7ì¼ íŠ¹ì„± ìƒì„±"""
        print("\n=== Step 3: ë°€ë„ ê¸°ë°˜ 7ì¼ íŠ¹ì„± ìƒì„± ===")
        
        all_features = {}
        processed_count = excluded_count = 0
        
        for user_id in all_user_ids:
            best_period = self.find_densest_7day_period(user_id, clean_step_data, lux_data, decibel_data, picture_data)
            
            if best_period is None:
                excluded_count += 1
                continue
            
            features = self.extract_7day_features(user_id, best_period, clean_step_data, lux_data, decibel_data, picture_data)
            
            if features:
                all_features[user_id] = features
                processed_count += 1
            else:
                excluded_count += 1
        
        print(f"ì²˜ë¦¬ëœ ì‚¬ìš©ì: {processed_count}ëª…, ì œì™¸ëœ ì‚¬ìš©ì: {excluded_count}ëª…")
        return all_features
    
    def extract_7day_features(self, user_id, best_period, clean_step_data, lux_data, decibel_data, picture_data):
        """íŠ¹ì • 7ì¼ ê¸°ê°„ì˜ ëª¨ë“  íŠ¹ì„± ì¶”ì¶œ"""
        
        start_date = min(best_period)
        end_date = max(best_period)
        
        base_start = datetime.strptime(str(start_date), '%Y%m%d')
        seven_days = [(base_start + timedelta(days=i)).strftime('%Y%m%d') for i in range(7)]
        seven_days = [int(date) for date in seven_days]
        
        features = {}
        # 1. ê±¸ìŒìˆ˜ íŠ¹ì„± (ê¸°ì¡´ê³¼ ë™ì¼)
        user_step_dict = {r['DATE']: r['DAILY_STEPS'] for r in clean_step_data if r['USER_ID'] == user_id}
        period_steps = [user_step_dict[d] for d in user_step_dict.keys() if start_date <= d <= end_date]
        period_step_avg = np.mean(period_steps) if period_steps else 0
        
        daily_steps = []
        for day in seven_days:
            if day in user_step_dict:
                daily_steps.append(user_step_dict[day])
            else:
                daily_steps.append(period_step_avg)
        
        for i, steps in enumerate(daily_steps):
            features[f'day{i+1}_steps'] = steps
    
        # LUX íŠ¹ì„± (ì „ëµ ì ìš©)
        daily_lux = self._process_sensor_data_with_strategy(
            user_id, seven_days, start_date, end_date, lux_data, 'LUX_TIME', 'LUX_VALUE', self.lux_strategy
        )
        for i, lux in enumerate(daily_lux):
            features[f'day{i+1}_lux'] = lux
        
        # DECIBEL íŠ¹ì„± (ì „ëµ ì ìš©)
        daily_decibel = self._process_sensor_data_with_strategy(
            user_id, seven_days, start_date, end_date, decibel_data, 'DB_TIME', 'DB_VALUE', self.decibel_strategy
        )
        for i, decibel in enumerate(daily_decibel):
            features[f'day{i+1}_decibel'] = decibel
        
        # PICTURE íŠ¹ì„± (ì „ëµ ì ìš©)
        daily_pictures = self._process_picture_data_with_strategy(
            user_id, seven_days, start_date, end_date, picture_data, self.picture_strategy
        )
        for i, pic_count in enumerate(daily_pictures):
            features[f'day{i+1}_pictures'] = pic_count
        
        # ìš”ì•½ í†µê³„ (missing ê°’ ì œì™¸í•˜ê³  ê³„ì‚°)
        clean_lux = [x for x in daily_lux if x != -999]
        clean_decibel = [x for x in daily_decibel if x != -999]
        clean_pictures = [x for x in daily_pictures if x != -999]
        
        features['avg_lux'] = np.mean(clean_lux) if clean_lux else 0
        features['std_lux'] = np.std(clean_lux) if len(clean_lux) > 1 else 0
        features['avg_decibel'] = np.mean(clean_decibel) if clean_decibel else 0
        features['std_decibel'] = np.std(clean_decibel) if len(clean_decibel) > 1 else 0
        features['avg_pictures'] = np.mean(clean_pictures) if clean_pictures else 0
        features['std_pictures'] = np.std(clean_pictures) if len(clean_pictures) > 1 else 0
        
        return features

    def _process_sensor_data_with_strategy(self, user_id, seven_days, start_date, end_date, sensor_data, time_col, value_col, strategy):
        """ì„¼ì„œ ë°ì´í„° ì²˜ë¦¬ (3ê°€ì§€ ì „ëµ ì§€ì›)"""
        if sensor_data.empty:
            return [0 if strategy == 'zero' else -999 if strategy == 'missing' else 0] * 7
        
        user_sensor = sensor_data[sensor_data['USER_ID'].astype(str) == str(user_id)]
        if len(user_sensor) == 0:
            return [0 if strategy == 'zero' else -999 if strategy == 'missing' else 0] * 7
        
        # period_avg ì „ëµì„ ìœ„í•œ ëŒ€ì²´ê°’ ê³„ì‚°
        period_values = []
        for _, row in user_sensor.iterrows():
            if pd.notna(row.get(time_col)):
                date = self.extract_date_from_timestamp(row[time_col])
                if date and start_date <= date <= end_date:
                    period_values.append(row[value_col])
        
        period_avg_value = np.mean(period_values) if period_values else 0
        
        # ì „ëµë³„ ëŒ€ì²´ê°’ ì„¤ì •
        if strategy == 'zero':
            default_value = 0
        elif strategy == 'period_avg':
            default_value = period_avg_value
        elif strategy == 'missing':
            default_value = -999  # ì¸¡ì • ì•ˆë¨ì„ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ìˆ˜ê°’
        else:
            default_value = 0
        
        # ì¼ë³„ ê°’ ìƒì„±
        daily_values = []
        for day in seven_days:
            day_values = []
            for _, row in user_sensor.iterrows():
                if pd.notna(row.get(time_col)):
                    date = self.extract_date_from_timestamp(row[time_col])
                    if date == day:
                        day_values.append(row[value_col])
            
            if day_values:
                daily_values.append(np.mean(day_values))
            else:
                daily_values.append(default_value)
        
        return daily_values

    def _process_picture_data_with_strategy(self, user_id, seven_days, start_date, end_date, picture_data, strategy):
        """ì‚¬ì§„ ë°ì´í„° ì²˜ë¦¬ (3ê°€ì§€ ì „ëµ ì§€ì›)"""
        if picture_data.empty:
            return [0 if strategy == 'zero' else -999 if strategy == 'missing' else 0] * 7
        
        user_pictures = picture_data[picture_data['USER_ID'].astype(str) == str(user_id)]
        if len(user_pictures) == 0:
            return [0 if strategy == 'zero' else -999 if strategy == 'missing' else 0] * 7
        
        # period_avg ì „ëµì„ ìœ„í•œ ê³„ì‚°
        period_counts = {}
        for _, row in user_pictures.iterrows():
            if pd.notna(row.get('PICTURE_DATE')):
                date = self.extract_date_from_timestamp(row['PICTURE_DATE'])
                if date and start_date <= date <= end_date:
                    period_counts[date] = period_counts.get(date, 0) + 1
        
        period_avg_value = np.mean(list(period_counts.values())) if period_counts else 0
        
        # ì „ëµë³„ ëŒ€ì²´ê°’ ì„¤ì •
        if strategy == 'zero':
            default_value = 0
        elif strategy == 'period_avg':
            default_value = period_avg_value
        elif strategy == 'missing':
            default_value = -999
        else:
            default_value = 0
        
        # ì¼ë³„ ê°’ ìƒì„±
        daily_pictures = []
        for day in seven_days:
            day_picture_count = 0
            has_data = False
            
            for _, row in user_pictures.iterrows():
                if pd.notna(row.get('PICTURE_DATE')):
                    date = self.extract_date_from_timestamp(row['PICTURE_DATE'])
                    if date == day:
                        day_picture_count += 1
                        has_data = True
            
            if has_data:
                daily_pictures.append(day_picture_count)
            else:
                daily_pictures.append(default_value)
        
        return daily_pictures
    def create_medical_features(self, join_survey_data, all_user_ids):
        """Step 4: ì˜ë£Œ/ìƒë‹´/ì¹˜ë£Œ íŠ¹ì„± ìƒì„± (ë‹¨ìˆœí™”)"""
        print("\n=== Step 4: ì˜ë£Œ/ìƒë‹´/ì¹˜ë£Œ íŠ¹ì„± ìƒì„± ===")
        
        medical_features = {}
        
        for user_id in all_user_ids:
            features = {}
            
            if join_survey_data.empty:
                # ê¸°ë³¸ê°’ ì„¤ì •
                features['consult_level'] = 0
                features['has_treatment'] = 0
                features['has_past_diagnosis'] = 0
            else:
                user_survey = join_survey_data[join_survey_data['USER_ID'].astype(str) == str(user_id)]
                
                if len(user_survey) == 0:
                    # í•´ë‹¹ ì‚¬ìš©ì ë°ì´í„° ì—†ìŒ
                    features['consult_level'] = 0
                    features['has_treatment'] = 0
                    features['has_past_diagnosis'] = 0
                else:
                    user_data = user_survey.iloc[0]
                    
                    # 1. ìƒë‹´ ë ˆë²¨ (0,1,2,3,4ë¡œ ìˆ˜ì •)
                    consult_value = user_data.get('USER_CONSULT', 'ì—†ìŒ')
                    consult_str = str(consult_value).strip() if pd.notna(consult_value) else 'ì—†ìŒ'
                    
                    if consult_str == 'ì—†ìŒ' or pd.isna(consult_value):
                        consult_level = 0
                    elif '1~5íšŒ' in consult_str:
                        consult_level = 1
                    elif '6~10íšŒ' in consult_str:
                        consult_level = 2
                    elif '11íšŒ ì´ìƒ' in consult_str:
                        if 'ì§€ì†ì ' in consult_str:
                            consult_level = 4  # 11íšŒ ì´ìƒ + ì§€ì†ì 
                        else:
                            consult_level = 3  # 11íšŒ ì´ìƒ
                    else:
                        consult_level = 0
                    
                    features['consult_level'] = consult_level
                    
                    # 2. ì¹˜ë£Œ ì—¬ë¶€ (ì´ì§„)
                    treat_value = user_data.get('USER_TREAT', 'ì•„ë‹ˆìš”')
                    features['has_treatment'] = 1 if str(treat_value).strip() == 'ì˜ˆ' else 0
                    
                    # 3. ê³¼ê±° ì§„ë‹¨ ê²½í—˜ (ë‹¨ìˆœ ì´ì§„) - ë­”ê°€ ì í˜€ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0
                    diagnosis_value = user_data.get('USER_TREAT_CATEGORY', 'ì—†ìŒ')
                    diagnosis_str = str(diagnosis_value).strip() if pd.notna(diagnosis_value) else 'ì—†ìŒ'
                    
                    if diagnosis_str in ['ì—†ìŒ', '', 'nan', 'NaN'] or pd.isna(diagnosis_value):
                        features['has_past_diagnosis'] = 0
                    else:
                        features['has_past_diagnosis'] = 1
            
            medical_features[user_id] = features
        
        # í†µê³„ ì¶œë ¥
        consult_counts = {}
        treatment_count = 0
        diagnosis_count = 0
        
        for user_features in medical_features.values():
            level = user_features['consult_level']
            consult_counts[level] = consult_counts.get(level, 0) + 1
            
            if user_features['has_treatment'] == 1:
                treatment_count += 1
                
            if user_features['has_past_diagnosis'] == 1:
                diagnosis_count += 1
        
        print(f"\nìƒë‹´ ë ˆë²¨ ë¶„í¬:")
        level_names = {0: "ì—†ìŒ", 1: "1-5íšŒ", 2: "6-10íšŒ", 3: "11íšŒ ì´ìƒ", 4: "11íšŒ ì´ìƒ+ì§€ì†ì "}
        for level, count in sorted(consult_counts.items()):
            print(f"  {level_names.get(level, f'ë ˆë²¨{level}')}: {count}ëª…")
        
        print(f"ì¹˜ë£Œ ë°›ì€ ê²½í—˜: {treatment_count}ëª…")
        print(f"ê³¼ê±° ì§„ë‹¨ ê²½í—˜: {diagnosis_count}ëª…")
        
        return medical_features
    
    def combine_features(self, seven_day_features, medical_features, labels_df):
        """Step 5: íŠ¹ì„± í†µí•©"""
        print("\n=== Step 5: íŠ¹ì„± í†µí•© ===")
        
        # êµì§‘í•© í™•ì¸
        seven_day_users = set(seven_day_features.keys())
        medical_users = set(medical_features.keys())
        label_users = set(labels_df['id'].values)
        
        print(f"7ì¼ íŠ¹ì„± ì‚¬ìš©ì: {len(seven_day_users)}ëª…")
        print(f"ì˜ë£Œ íŠ¹ì„± ì‚¬ìš©ì: {len(medical_users)}ëª…")
        print(f"ë¼ë²¨ íŒŒì¼ ì‚¬ìš©ì: {len(label_users)}ëª…")
        
        final_users = seven_day_users & medical_users & label_users
        print(f"ìµœì¢… ì‚¬ìš©ì: {len(final_users)}ëª…")
        
        feature_matrix = []
        labels = []
        user_ids = []
        
        for user_id in final_users:
            # 7ì¼ íŠ¹ì„±ê³¼ ì˜ë£Œ íŠ¹ì„± í†µí•©
            features = {}
            features.update(seven_day_features[user_id])
            features.update(medical_features[user_id])
            
            user_label = labels_df[labels_df['id'] == user_id]['group'].iloc[0]
            
            feature_matrix.append(list(features.values()))
            labels.append(user_label)
            user_ids.append(user_id)
        
        # íŠ¹ì„± ì´ë¦„ë“¤ ìƒì„±
        if final_users:
            sample_user = next(iter(final_users))
            sample_features = {}
            sample_features.update(seven_day_features[sample_user])
            sample_features.update(medical_features[sample_user])
            feature_names = list(sample_features.keys())
        else:
            feature_names = []
        
        print(f"ì´ íŠ¹ì„± ìˆ˜: {len(feature_names)}ê°œ")
        print("íŠ¹ì„± êµ¬ì„±:")
        print("  - ì¼ë³„ ê±¸ìŒìˆ˜ (7ê°œ): day1_steps ~ day7_steps")
        print("  - ì¼ë³„ LUX (7ê°œ): day1_lux ~ day7_lux")
        print("  - ì¼ë³„ DECIBEL (7ê°œ): day1_decibel ~ day7_decibel")
        print("  - ì¼ë³„ ì‚¬ì§„ìˆ˜ (7ê°œ): day1_pictures ~ day7_pictures")
        print("  - ìš”ì•½ í†µê³„ (9ê°œ): avg/std íŠ¹ì„±ë“¤")
        print("  - ìƒë‹´ ë ˆë²¨ (1ê°œ, 0-4): consult_level")
        print("  - ì¹˜ë£Œ ì—¬ë¶€ (1ê°œ, 0-1): has_treatment")
        print("  - ê³¼ê±° ì§„ë‹¨ (1ê°œ, 0-1): has_past_diagnosis")
        
        return np.array(feature_matrix), np.array(labels), user_ids, feature_names


class RandomForestTrainer:
    """ëœë¤í¬ë ˆìŠ¤íŠ¸ í•™ìŠµ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.model = None
    
    def train_model(self, X, y, feature_names):
        """ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ"""
        print("\n=== ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ ===")
        
        # ë¼ë²¨ ì¸ì½”ë”©
        y_encoded = self.label_encoder.fit_transform(y)
        label_names = self.label_encoder.classes_
        print(f"í´ë˜ìŠ¤: {label_names}")
        
        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        unique_labels, label_counts = np.unique(y, return_counts=True)
        print("\ní´ë˜ìŠ¤ ë¶„í¬:")
        for label, count in zip(unique_labels, label_counts):
            print(f"  {label}: {count}ëª… ({count/len(y)*100:.1f}%)")
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ëœë¤í¬ë ˆìŠ¤íŠ¸ í•™ìŠµ
        self.model = RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            class_weight='balanced',
            random_state=42
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred = self.model.predict(X_test_scaled)
        
        print("\n=== ëª¨ë¸ ì„±ëŠ¥ ===")
        print(f"í›ˆë ¨ ì •í™•ë„: {self.model.score(X_train_scaled, y_train):.3f}")
        print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {self.model.score(X_test_scaled, y_test):.3f}")
        
        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5)
        print(f"5-fold CV í‰ê· : {cv_scores.mean():.3f} (Â±{cv_scores.std()*2:.3f})")
        
        # ë¶„ë¥˜ ë¦¬í¬íŠ¸
        print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
        print(classification_report(y_test, y_pred, target_names=label_names))
        
        # íŠ¹ì„± ì¤‘ìš”ë„
        feature_importance = pd.DataFrame({
            'feature': feature_names,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\níŠ¹ì„± ì¤‘ìš”ë„ TOP 15:")
        print(feature_importance.head(15))
        
        return self.model, feature_importance


class PipelineRunner:
    """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í´ë˜ìŠ¤"""
    
    def __init__(self, picture_strategy='zero', decibel_strategy='period_avg', lux_strategy='period_avg'):
        self.preprocessor = EnhancedDataPreprocessor(picture_strategy, decibel_strategy, lux_strategy)
        self.trainer = RandomForestTrainer()
    
    def save_processed_data(self, X, y, user_ids, feature_names):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        print("\n=== ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥ ===")
        
        processed_df = pd.DataFrame(X, columns=feature_names)
        processed_df.insert(0, 'USER_ID', user_ids)
        processed_df.insert(1, 'GROUP', y)
        
        # ìƒë‹´/ì¹˜ë£Œ ì˜ë¯¸ ì¶”ê°€
        level_meaning = {0: "ì—†ìŒ", 1: "1-5íšŒ", 2: "6-10íšŒ", 3: "11íšŒ ì´ìƒ", 4: "11íšŒ ì´ìƒ+ì§€ì†ì "}
        if 'consult_level' in processed_df.columns:
            processed_df['ìƒë‹´ë ˆë²¨ì˜ë¯¸'] = processed_df['consult_level'].map(level_meaning)
        
        if 'has_treatment' in processed_df.columns:
            processed_df['ì¹˜ë£Œì—¬ë¶€ì˜ë¯¸'] = processed_df['has_treatment'].map({0: "ì—†ìŒ", 1: "ìˆìŒ"})
            
        if 'has_past_diagnosis' in processed_df.columns:
            processed_df['ê³¼ê±°ì§„ë‹¨ì˜ë¯¸'] = processed_df['has_past_diagnosis'].map({0: "ì—†ìŒ", 1: "ìˆìŒ"})
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"ë‹¨ìˆœí™”_ë°”ì´ì˜¤ë§ˆì»¤_ë°ì´í„°_{timestamp}.xlsx"
        processed_df.to_excel(filename, index=False)
        
        print(f"ì €ì¥ ì™„ë£Œ: {filename}")
        return filename
    
    def run_pipeline(self, data_file, label_file):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ì™„ì „í•œ ë””ì§€í„¸ ë°”ì´ì˜¤ë§ˆì»¤ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("í¬í•¨ íŠ¹ì„±:")
        print("  - ë°€ë„ ê¸°ë°˜ ìµœì  7ì¼ êµ¬ê°„ ì„ íƒ")
        print("  - 7ì¼ê°„ ì¼ë³„ íŒ¨í„´ (ê±¸ìŒìˆ˜, LUX, DECIBEL, ì‚¬ì§„ìˆ˜)")
        print("  - ìƒë‹´ ë ˆë²¨ (0,1,2,3)")
        print("  - ì¹˜ë£Œ ì—¬ë¶€ (0,1)")
        print("  - ì§„ë‹¨ëª…ë³„ ì´ì§„ íŠ¹ì„±")
        
        # 1. ë°ì´í„° ë¡œë“œ
        data_sheets, labels_df = self.preprocessor.load_data(data_file, label_file)
        
        # 2. STEP ë°ì´í„° ì „ì²˜ë¦¬
        clean_step_data = self.preprocessor.process_step_data(data_sheets['STEP'])
        all_user_ids = labels_df['id'].unique()
        
        # 3. ë°€ë„ ê¸°ë°˜ 7ì¼ íŠ¹ì„± ìƒì„±
        seven_day_features = self.preprocessor.create_7day_features(
            clean_step_data, data_sheets['LUX'], data_sheets['DECIBEL'], 
            data_sheets['PICTURE'], all_user_ids
        )
        
        # 4. ì˜ë£Œ/ìƒë‹´/ì¹˜ë£Œ íŠ¹ì„± ìƒì„±
        medical_features = self.preprocessor.create_medical_features(
            data_sheets['JOIN SURVEY'], all_user_ids
        )
        
        # 5. íŠ¹ì„± í†µí•©
        X, y, user_ids, feature_names = self.preprocessor.combine_features(
            seven_day_features, medical_features, labels_df
        )
        
        if len(X) == 0:
            print("ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None, None, None
        
        # 6. ëª¨ë¸ í•™ìŠµ
        model, feature_importance = self.trainer.train_model(X, y, feature_names)
        
        # 7. ë°ì´í„° ì €ì¥
        self.save_processed_data(X, y, user_ids, feature_names)
        
        # 8. ê²°ê³¼ ë¶„ì„
        self.analyze_results(feature_importance)
        
        print("\nì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        return model, feature_importance, X, y, user_ids
    
    def analyze_results(self, feature_importance):
        """ìƒì„¸ ê²°ê³¼ ë¶„ì„"""
        print("\në³€ìˆ˜ë³„ ì¤‘ìš”ë„ ë¶„ì„:")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ìš”ë„ ì§‘ê³„
        categories = {
            'steps': [f for f in feature_importance['feature'] if 'steps' in f],
            'lux': [f for f in feature_importance['feature'] if 'lux' in f],
            'decibel': [f for f in feature_importance['feature'] if 'decibel' in f],
            'pictures': [f for f in feature_importance['feature'] if 'pictures' in f],
            'medical': [f for f in feature_importance['feature'] if f in ['consult_level', 'has_treatment'] or f.startswith('diagnosis_')]
        }
        
        category_importance = {}
        for category, features in categories.items():
            importance_sum = feature_importance[feature_importance['feature'].isin(features)]['importance'].sum()
            category_importance[category] = importance_sum
        
        # ì¤‘ìš”ë„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_categories = sorted(category_importance.items(), key=lambda x: x[1], reverse=True)
        
        print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ìš”ë„:")
        category_names = {
            'steps': 'ê±¸ìŒìˆ˜',
            'lux': 'ì¡°ë„(LUX)', 
            'decibel': 'ì†ŒìŒ(DECIBEL)',
            'pictures': 'ì‚¬ì§„ìˆ˜',
            'medical': 'ì˜ë£Œ/ìƒë‹´'
        }
        
        for i, (category, importance) in enumerate(sorted_categories, 1):
            print(f"   {i}. {category_names[category]}: {importance:.3f}")
        
        # ì˜ë£Œ íŠ¹ì„± ì„¸ë¶€ ë¶„ì„
        medical_features = feature_importance[
            (feature_importance['feature'] == 'consult_level') |
            (feature_importance['feature'] == 'has_treatment') |
            (feature_importance['feature'] == 'has_past_diagnosis')
        ].sort_values('importance', ascending=False)
        
        if len(medical_features) > 0:
            print("\nğŸ’Š ì˜ë£Œ íŠ¹ì„±ë³„ ì¤‘ìš”ë„:")
            for _, row in medical_features.iterrows():
                feature_name = row['feature']
                if feature_name == 'consult_level':
                    display_name = 'ìƒë‹´ ë ˆë²¨ (0-4)'
                elif feature_name == 'has_treatment':
                    display_name = 'ì¹˜ë£Œ ì—¬ë¶€'
                elif feature_name == 'has_past_diagnosis':
                    display_name = 'ê³¼ê±° ì§„ë‹¨ ê²½í—˜'
                else:
                    display_name = feature_name
                
                print(f"   {display_name}: {row['importance']:.3f}")
        
        print(f"\në¶„ì„ ê²°ê³¼:")
        top_category = sorted_categories[0][0]
        print(f"   {category_names[top_category]}ì´ ê°€ì¥ ì¤‘ìš”í•œ ì˜ˆì¸¡ ì¸ìì…ë‹ˆë‹¤!")


# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # ë‹¤ì–‘í•œ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
    
    # ì„¤ì • 1: ì‚¬ì§„ì€ 0, ë‚˜ë¨¸ì§€ëŠ” ê¸°ê°„ í‰ê·  (ê¸°ë³¸)
    #print("=== ì„¤ì • 1: ê¸°ë³¸ (ì‚¬ì§„=0, ì„¼ì„œ=ê¸°ê°„í‰ê· ) ===")
    runner1 = PipelineRunner(picture_strategy='period_avg', decibel_strategy='period_avg', lux_strategy='period_avg') #0.757 (Â±0.114)
    
    # ì„¤ì • 2: ëª¨ë“  ë³€ìˆ˜ë¥¼ ê¸°ê°„ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
    #print("\n=== ì„¤ì • 2: ëª¨ë“  ë³€ìˆ˜ ê¸°ê°„í‰ê·  ëŒ€ì²´ ===")
    #runner2 = PipelineRunner(picture_strategy='period_avg', decibel_strategy='period_avg', lux_strategy='period_avg')# 5-fold CV í‰ê· : 0.743 (Â±0.146)
    runner2 = PipelineRunner(picture_strategy='zero', decibel_strategy='zero', lux_strategy='zero') #5-fold CV í‰ê· : 0.786 (Â±0.090)
    runner_missing = PipelineRunner(
    picture_strategy='missing', 
    decibel_strategy='missing', 
    lux_strategy='missing'
    )
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    data_file = r"C:\Users\parkm\OneDrive - dgu.ac.kr\AI_LAB\U-health\lifelog\Lifelog\data\231123-DATA.xlsx"
    label_file = r"C:\Users\parkm\OneDrive - dgu.ac.kr\AI_LAB\U-health\lifelog\Lifelog\data\231123-LABEL.xlsx"
    
    try:
        # ì›í•˜ëŠ” ì„¤ì • ì„ íƒí•´ì„œ ì‹¤í–‰
        model, feature_importance, X, y, user_ids = runner1.run_pipeline(data_file, label_file)
        
        if model is not None:
            print(f"\nì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ìµœì¢… ë°ì´í„°ì…‹: {len(X)}ëª…ì˜ ì‚¬ìš©ì, {X.shape[1]}ê°œ íŠ¹ì„±")
            print("íŠ¹ì„± êµ¬ì„±:")
            print("  - 7ì¼ ìƒì²´ì‹ í˜¸ íŒ¨í„´: 56ê°œ (28ê°œ ê°’ + 28ê°œ ì¸¡ì •ì—¬ë¶€)")
            print("  - ìš”ì•½ í†µê³„: 13ê°œ")
            print("  - ìƒë‹´/ì¹˜ë£Œ ì •ë³´: 3ê°œ")
        else:
            print("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("íŒŒì¼ ê²½ë¡œì™€ ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")